{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\n",
    "batch_size = 256\n",
    "num_workers = 0   # 对于Windows用户，这里应设置为0，否则会出现多线程错误\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  \n",
    "     # 这一步取决于后续的数据读取方式，如果使用内置数据集读取方式则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式二：读入csv格式的数据，自行构建Dataset类\n",
    "# csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a1073a1670>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        # x = nn.functional.normalize(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "def val(epoch):       \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, 1)\n",
    "            gt_labels.append(label.cpu().data.numpy())\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    val_loss = val_loss/len(test_loader.dataset)\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.657413\n",
      "Epoch: 1 \tValidation Loss: 0.437284, Accuracy: 0.841600\n",
      "Epoch: 2 \tTraining Loss: 0.415032\n",
      "Epoch: 2 \tValidation Loss: 0.336671, Accuracy: 0.878000\n",
      "Epoch: 3 \tTraining Loss: 0.352575\n",
      "Epoch: 3 \tValidation Loss: 0.311589, Accuracy: 0.887700\n",
      "Epoch: 4 \tTraining Loss: 0.323245\n",
      "Epoch: 4 \tValidation Loss: 0.300744, Accuracy: 0.890400\n",
      "Epoch: 5 \tTraining Loss: 0.304321\n",
      "Epoch: 5 \tValidation Loss: 0.276774, Accuracy: 0.897600\n",
      "Epoch: 6 \tTraining Loss: 0.285771\n",
      "Epoch: 6 \tValidation Loss: 0.256736, Accuracy: 0.907200\n",
      "Epoch: 7 \tTraining Loss: 0.272577\n",
      "Epoch: 7 \tValidation Loss: 0.246640, Accuracy: 0.908900\n",
      "Epoch: 8 \tTraining Loss: 0.261127\n",
      "Epoch: 8 \tValidation Loss: 0.247354, Accuracy: 0.908100\n",
      "Epoch: 9 \tTraining Loss: 0.251136\n",
      "Epoch: 9 \tValidation Loss: 0.227467, Accuracy: 0.913700\n",
      "Epoch: 10 \tTraining Loss: 0.242432\n",
      "Epoch: 10 \tValidation Loss: 0.232056, Accuracy: 0.912700\n",
      "Epoch: 11 \tTraining Loss: 0.231180\n",
      "Epoch: 11 \tValidation Loss: 0.225918, Accuracy: 0.914200\n",
      "Epoch: 12 \tTraining Loss: 0.223021\n",
      "Epoch: 12 \tValidation Loss: 0.221200, Accuracy: 0.920200\n",
      "Epoch: 13 \tTraining Loss: 0.216659\n",
      "Epoch: 13 \tValidation Loss: 0.218659, Accuracy: 0.920300\n",
      "Epoch: 14 \tTraining Loss: 0.207354\n",
      "Epoch: 14 \tValidation Loss: 0.211871, Accuracy: 0.921200\n",
      "Epoch: 15 \tTraining Loss: 0.202978\n",
      "Epoch: 15 \tValidation Loss: 0.201596, Accuracy: 0.925000\n",
      "Epoch: 16 \tTraining Loss: 0.194762\n",
      "Epoch: 16 \tValidation Loss: 0.223763, Accuracy: 0.918500\n",
      "Epoch: 17 \tTraining Loss: 0.191151\n",
      "Epoch: 17 \tValidation Loss: 0.203954, Accuracy: 0.925600\n",
      "Epoch: 18 \tTraining Loss: 0.186226\n",
      "Epoch: 18 \tValidation Loss: 0.208308, Accuracy: 0.923200\n",
      "Epoch: 19 \tTraining Loss: 0.179852\n",
      "Epoch: 19 \tValidation Loss: 0.199619, Accuracy: 0.926000\n",
      "Epoch: 20 \tTraining Loss: 0.175221\n",
      "Epoch: 20 \tValidation Loss: 0.201983, Accuracy: 0.925800\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./FahionModel.pkl\"\n",
    "torch.save(model, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('graph_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cde2bbb51816c88edb1b784907a17de6838e05ececb3fda4268a507f791f6d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
